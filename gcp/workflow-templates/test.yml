#gcloud dataproc workflow-templates import devfest   --region europe-west1 --source test.yml
#gcloud dataproc workflow-templates instantiate-from-file --file test.yml --region europe-west1
jobs:
- sparkJob:
    jarFileUris:
    - gs://devfest-jars/spark-examples-1.0-SNAPSHOT.jar
    mainClass: com.sparkbyexamples.spark.SparkSessionTest
    properties:
      spark.driver.cores: '1'
      spark.driver.memory: 2g
      spark.executor.instances: '1'
      spark.yarn.am.cores: '2'
      spark.yarn.am.memory: 2g
      spark.yarn.queue: default
  stepId: devfest-spark-example
placement:
  managedCluster:
    clusterName: devfest-workflow
    config:
      configBucket: devfest-dataproc
      gceClusterConfig:
        internalIpOnly: true
        serviceAccount: devfest@sandbox-233511.iam.gserviceaccount.com
        subnetworkUri: https://www.googleapis.com/compute/v1/projects/sandbox-233511/regions/europe-west1/subnetworks/sandbox-subnet
        zoneUri: europe-west1-d
      initializationActions:
      - executableFile: gs://devfest-dataproc/livy-initialization/custom_livy.sh
        executionTimeout: 600s
      masterConfig:
        diskConfig:
          bootDiskSizeGb: 50
          bootDiskType: pd-ssd
        machineTypeUri: n1-standard-4
        numInstances: 1
      softwareConfig:
        imageVersion: 1.3-deb9
      workerConfig:
        machineTypeUri: n1-standard-8
        diskConfig:
          bootDiskSizeGb: 50
          bootDiskType: pd-ssd
        numInstances: 2